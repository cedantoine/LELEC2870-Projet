{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import matplotlib\n",
    "from matplotlib import pyplot as plt\n",
    "try:\n",
    "    import seaborn as sns\n",
    "    use_seaborn = True\n",
    "    sns.set()\n",
    "except:\n",
    "    use_seaborn = False\n",
    "showfig = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "X1 = pd.read_csv(\"X1.csv\")\n",
    "Y1 = pd.read_csv(\"Y1.csv\",header=None,names =['shares'])\n",
    "\n",
    "if showfig:\n",
    "    fig = plt.figure(figsize=(6.4*2,4.8*6))\n",
    "    gs  = fig.add_gridspec(nrows=12, ncols=5)\n",
    "    for (i,header) in enumerate(X1.columns):\n",
    "        ax = fig.add_subplot(gs[int(i/5),i%5])\n",
    "        ax.scatter(X1[header],Y1.values, s=5)\n",
    "        ax.set_xlabel(header)\n",
    "    fig.tight_layout()\n",
    "\n",
    "X1_val = X1.values\n",
    "Y1_val = Y1.values\n",
    "\n",
    "X1_train, X1_test, Y1_train, Y1_test = train_test_split(X1_val, Y1_val,random_state=1, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prediction\n",
    "def scoref1(ytrue, ypred, th):\n",
    "    return sklearn.metrics.f1_score(ytrue>th, ypred>th)\n",
    "\n",
    "def scoreregression(ytrue, ypred):\n",
    "    scores = [\n",
    "        scoref1(ytrue, ypred, th=th) for th in [ 500, 1400, 5000, 10000]\n",
    "    ]\n",
    "    return np.mean(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4746420107120262\n"
     ]
    }
   ],
   "source": [
    "from sklearn import linear_model\n",
    "\n",
    "# Select features\n",
    "corr = np.corrcoef(np.concatenate((np.transpose(X1_val),np.transpose(Y1_val))))\n",
    "idxs = np.argpartition(corr[:][58], -4)[-4:]\n",
    "X1_train_ = X1_train[:,idxs[:-1]]\n",
    "X1_test_  = X1_test[:,idxs[:-1]]\n",
    "\n",
    "# Create linear regression object\n",
    "regr = linear_model.LinearRegression()\n",
    "# Train the model using the training sets\n",
    "regr.fit(X1_train_, Y1_train)\n",
    "# Make predictions using the testing set\n",
    "Y1_pred = regr.predict(X1_test_)\n",
    "\n",
    "print(scoreregression(Y1_test, Y1_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minimum number of components that preserve 0.95 of the variance = 36 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "\n",
    "# Initiate StandardScaler\n",
    "scaler = StandardScaler(copy=True,with_mean=True,with_std=True)\n",
    "X1_normalized = scaler.fit_transform(X1_train)\n",
    "X1_ = X1_normalized.copy()\n",
    "\n",
    "# Initialize PCA\n",
    "pca = PCA(n_components=X1.shape[-1])\n",
    "\n",
    "data_transformed = pca.fit_transform(X1_, Y1_train)\n",
    "eig_val = pca.explained_variance_\n",
    "eig_vec = pca.components_\n",
    "\n",
    "# Compute an array E, where E(P) indicates the variance captured in the first P component.\n",
    "E = np.array([eig_val[:p+1].sum()/eig_val.sum() for p in range(len(eig_val))])\n",
    "tau = 0.95 # Threshold\n",
    "\n",
    "# Find the minimum P that captures \\tau portion of the variance\n",
    "P = np.where(E>tau)[0][0] +1\n",
    "print('Minimum number of components that preserve {} of the variance = {} \\n' .format(tau,P))\n",
    "\n",
    "if showfig:\n",
    "    fig = plt.figure(figsize=(20,5))\n",
    "    ax1 = fig.add_subplot() #(131)\n",
    "    ax1.plot(np.arange(1,E.shape[0]+1), E, 'o-', markersize=8, color='blue', alpha=0.5)\n",
    "    ax1.set_xlabel('number of components')\n",
    "    ax1.set_ylabel('Preserved variance')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.49245950735159555\n"
     ]
    }
   ],
   "source": [
    "pca.n_components = 5\n",
    "X1_ = X1_normalized.copy()\n",
    "X1_train_ = pca.fit_transform(X1_, Y1_train)\n",
    "X1_test_  = pca.fit_transform(\n",
    "                scaler.fit_transform(X1_test))\n",
    "\n",
    "knn = KNeighborsRegressor(20)\n",
    "# knn.fit(X1_train_, Y1_train.ravel())\n",
    "knn.fit(X1_train_, Y1_train)\n",
    "Y1_pred = knn.predict(X1_test_)\n",
    "print(scoreregression(Y1_test, Y1_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4818855723718007\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/gregoire/WD Elements 10B8/studies/MA/lelec2870_machine_learning/Sessions/myenv/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:582: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "#https://towardsdatascience.com/deep-neural-multilayer-perceptron-mlp-with-scikit-learn-2698e77155e\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "\n",
    "pca.n_components = 5\n",
    "X1_ = X1_normalized.copy()\n",
    "X1_train_ = pca.fit_transform(X1_, Y1_train)\n",
    "X1_test_  = pca.fit_transform(\n",
    "                scaler.fit_transform(X1_test))\n",
    "\n",
    "reg = MLPRegressor(hidden_layer_sizes=(64,64,64),\n",
    "                   activation=\"relu\",\n",
    "                   random_state=1,\n",
    "                   max_iter=100)\n",
    "reg.fit(X1_train_, Y1_train.ravel())\n",
    "Y1_pred = reg.predict(X1_test_)\n",
    "print(scoreregression(Y1_test, Y1_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/gregoire/WD Elements 10B8/studies/MA/lelec2870_machine_learning/Sessions/myenv/lib/python3.8/site-packages/sklearn/svm/_base.py:246: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn('Solver terminated early (max_iter=%i).'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.36832540724427637\n"
     ]
    }
   ],
   "source": [
    "# scikit-learn.org/stable/auto_examples/svm/plot_rbf_parameters.html\n",
    "# ++ CHOOSE BEST PARAMETERS TO FIT\n",
    "#     scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "pca.n_components = 5\n",
    "scaler = StandardScaler()\n",
    "\n",
    "X1_train_ = scaler.fit_transform(X1_train)\n",
    "X1_test_  = scaler.fit_transform(X1_test)\n",
    "\n",
    "# X1_train_ = pca.fit_transform(scaler.fit_transform(X1_train), Y1_train)\n",
    "# X1_test_  = pca.fit_transform(scaler.fit_transform(X1_test))\n",
    "\n",
    "\n",
    "svc = SVC(C=1,\n",
    "          gamma='auto',\n",
    "          max_iter=100)\n",
    "svc.fit(X1_train_, Y1_train.ravel())\n",
    "Y1_pred = svc.predict(X1_test_)\n",
    "print(scoreregression(Y1_test, Y1_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
